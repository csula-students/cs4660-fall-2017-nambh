{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lab 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get our imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import tree #see http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get our data: we'll use the iris data set for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "print X.shape\n",
    "print y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the first 5 rows\n",
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and test sets\n",
    "\n",
    "## The reason we do this is that sometimes our classifier will fit the data so well that it reflects the ideosyncracies of our sample, and not generalize well. This is called overfitting. To get a good idea of how the classifier would do on data it hasn't seen, we reserve some data that we will not use for training and test it out on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\") #see http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To see how we did, test on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy on training data:', 1.0)\n",
      "('Accuracy on test data:', 0.97999999999999998)\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "acc_train = clf.score(X_train, y_train)\n",
    "acc_test = clf.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on training data:\", acc_train)\n",
    "print(\"Accuracy on test data:\", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out a different min samples split and see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy with min split = 2:', 0.97999999999999998)\n",
      "('Accuracy with min split = 50:', 0.97999999999999998)\n"
     ]
    }
   ],
   "source": [
    "clf1 = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_split=2)\n",
    "clf2 = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_split=50)\n",
    "\n",
    "clf1.fit(X_train, y_train)\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "acc_min_samples_split_2 = clf1.score(X_test, y_test)\n",
    "acc_min_samples_split_50 = clf2.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy with min split = 2:\", acc_min_samples_split_2)\n",
    "print(\"Accuracy with min split = 50:\", acc_min_samples_split_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree.export_graphviz(clf, out_file='imgs/tree.dot')\n",
    "\n",
    "! dot -Tpng imgs/tree.dot -o imgs/result.png\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/result.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  1.  0.  1.  1.  0.  0.  1.  0.  0.]\n",
      " [ 0.  1.  1.  0.  1.  0.  1.  0.  1.  0.  0.]\n",
      " [ 0.  1.  1.  0.  1.  0.  1.  0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.  1.  0.  0.  0.  0.  3.  0.]\n",
      " [ 0.  1.  1.  0.  1.  1.  0.  0.  0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "my_data =  np.loadtxt('willwait_data.csv', dtype=str, delimiter=',')\n",
    "print(my_data[:5])\n",
    "\n",
    "#Need to convert everything to numerical values\n",
    "my_data[my_data=='No'] = 0\n",
    "my_data[my_data =='None'] = 0\n",
    "my_data[my_data=='$'] = 0\n",
    "my_data[my_data=='Mexican'] = 0\n",
    "my_data[my_data=='10'] = 0\n",
    "\n",
    "my_data[my_data=='Yes'] = 1\n",
    "my_data[my_data=='Some'] = 1\n",
    "my_data[my_data=='$$'] = 1\n",
    "my_data[my_data=='Thai'] = 1\n",
    "my_data[my_data=='30'] = 1\n",
    "\n",
    "my_data[my_data=='Full'] = 2\n",
    "my_data[my_data=='$$$'] = 2\n",
    "my_data[my_data=='Burger'] = 2\n",
    "my_data[my_data=='60'] = 2\n",
    "\n",
    "my_data[my_data=='Italian'] = 3\n",
    "\n",
    "my_data = np.delete(my_data, 0, 1) \n",
    "my_data = np.delete(my_data, 0, 0).astype('float64') \n",
    "\n",
    "print(my_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.\n",
      "  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "restaurant_y = my_data[:, 0]\n",
    "print(restaurant_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  0.  1.  1.  0.  0.  1.  0.  0.]\n",
      " [ 1.  1.  0.  1.  0.  1.  0.  1.  0.  0.]\n",
      " [ 1.  1.  0.  1.  0.  1.  0.  1.  1.  0.]\n",
      " [ 1.  1.  0.  1.  0.  0.  0.  0.  3.  0.]\n",
      " [ 1.  1.  0.  1.  1.  0.  0.  0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "restaurant_X = my_data[:, 1:]\n",
    "print(restaurant_X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfr = tree.DecisionTreeClassifier(criterion=\"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(restaurant_X, restaurant_y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfr.fit(Xr_train, yr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy on training data:', 1.0)\n",
      "('Accuracy on test data:', 0.76923076923076927)\n"
     ]
    }
   ],
   "source": [
    "accr_train = clfr.score(Xr_train, yr_train)\n",
    "accr_test = clfr.score(Xr_test, yr_test)\n",
    "print(\"Accuracy on training data:\", accr_train)\n",
    "print(\"Accuracy on test data:\", accr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree.export_graphviz(clfr, out_file='imgs/treer.dot')\n",
    "\n",
    "! dot -Tpng imgs/treer.dot -o imgs/resultr.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/resultr.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
